\section{Classification of AT-TPC events}

The training procedure for classification using a semi-supervised regime as the one we'll apply necessitates the same strict separation of labeled data for the classification step as when considering ordinary classification tasks. To emulate the real-data case we set a subset of the simulated data to be labeled and treat the rest as unlabeled data. We chose this partition to be $15\%$ of each class. We denote this subset and its associated labels as $\gamma_L=(\mathbf{X}_L, \mathbf{y}_L)$, the entire dataset which we will denote as $\mathbf{X}_F$. To clarify please note that $\mathbf{X}_L \subset \mathbf{X}_F$. Furthermore, the tuple $\gamma_L$ has to be split in training and test sets. The test partition is set to be $30\%$ of the samples. The hyperparameters were tuned with the \lstinline{RandomSearch} architecture which searches in a semi structured way over all the parameters given in table \ref{tab:convae_hyperparams} we list the experiments with their corresponding proton $f1$ score in appendix \ref{tab:convae_randomsearch}. We optimize the classification performance using $M=40$ semi-structured random experiments. To illustrate the difference in quality and convergence of the runs we show the plot of the resulting loss curves of the highest $N=10$ runs in figure \ref{fig:sim_clf_loss}. In the figure lighter colors represent higher proton $f1$ scores, and as such the same color across the reconstruction and latent losses represent the same experiment. We also denote different scales and corresponding markers for the reconstruction and latent losses. We observe that in the top 10 performing runs there are no versions of the model that maintains a VAE-style Kullback Leibler loss on the latent space. And that the very highest performing model maintains no regularization at all, while considerably more complex than the runners up as seen from appendix \ref{tab:convae_randomsearch}.

\subsection{Convolutional Autoencoder results}

\subsection{DRAW results}